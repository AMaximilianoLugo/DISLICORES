{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "# Configuración de la base de datos\n",
    "database_config = {\n",
    "    'server': 'dislicores-1.cxc0gcgy4dsz.us-east-2.rds.amazonaws.com,1433',  \n",
    "    'database': 'dislicores-1', \n",
    "    'username': 'admin',  \n",
    "    'password': 'KingKong9#_9+',  \n",
    "}\n",
    "\n",
    "# Crear cadena de conexión\n",
    "connection_string = f\"mssql+pyodbc://{database_config['username']}:{database_config['password']}@{database_config['server']}/{database_config['database']}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "class DataHandler(FileSystemEventHandler):\n",
    "    def __init__(self, engine):\n",
    "        self.engine = engine\n",
    "\n",
    "    def on_created(self, event):\n",
    "        if event.is_directory or not event.src_path.endswith(\".csv\"):\n",
    "            return\n",
    "        self.process_new_file(event.src_path)\n",
    "\n",
    "    def on_modified(self, event):\n",
    "        if event.is_directory or not event.src_path.endswith(\".csv\"):\n",
    "            return\n",
    "        self.process_new_file(event.src_path)\n",
    "\n",
    "    def process_new_file(self, file_path):\n",
    "        try:\n",
    "            new_data = pd.read_csv(file_path)\n",
    "            new_data = new_data.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "            # Convertir columnas que contengan la palabra 'date' a formato datetime\n",
    "            for column in new_data.columns:\n",
    "                if 'date' in column.lower():\n",
    "                    new_data[column] = pd.to_datetime(new_data[column], errors='coerce')\n",
    "\n",
    "            table_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "            # Obtener el nombre de la columna ID específica\n",
    "            id_column = self.get_id_column(table_name)\n",
    "\n",
    "            # Verificar que la columna ID exista en el DataFrame\n",
    "            if id_column not in new_data.columns:\n",
    "                print(f\"Error: La columna '{id_column}' no existe en el archivo {file_path}\")\n",
    "                return\n",
    "\n",
    "            # Cargar los datos existentes de la base de datos\n",
    "            existing_data = pd.read_sql(f\"SELECT * FROM {table_name}\", self.engine)\n",
    "\n",
    "            # Identificar filas nuevas (basado en id_column)\n",
    "            new_rows = new_data[~new_data[id_column].isin(existing_data[id_column])]\n",
    "\n",
    "            # Verificar integridad referencial para 'Inventario_inicialID' si es necesario\n",
    "            if table_name == 'VentasFinales':\n",
    "                inventario_inicial_ids = pd.read_sql(\"SELECT InventoryInicialID FROM InventarioInicial2016\", self.engine)\n",
    "                valid_ids = inventario_inicial_ids['InventoryInicialID']\n",
    "                new_rows = new_rows[new_rows['InventoryInicialID'].isin(valid_ids)]\n",
    "\n",
    "            # Insertar datos nuevos en la base de datos\n",
    "            if not new_rows.empty:\n",
    "                new_rows.to_sql(table_name, self.engine, if_exists='append', index=False)\n",
    "                print(f\"Se han insertado {len(new_rows)} filas nuevas en la tabla {table_name}\")\n",
    "            else:\n",
    "                print(f\"No hay filas nuevas para insertar en la tabla {table_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar el archivo {file_path}: {e}\")\n",
    "\n",
    "    def get_id_column(self, table_name):\n",
    "        id_columns = {\n",
    "            'VentasFinales': 'VentasID',\n",
    "            'DetalleCompra': 'DetalleCompraID',\n",
    "            'InventarioFinal2016': 'InventoryFinalID',\n",
    "            'InventarioInicial2016': 'InventoryInicialID',\n",
    "            'Producto': 'BrandID',\n",
    "            'FacturaCompras': 'CompraID',\n",
    "        }\n",
    "        return id_columns.get(table_name, 'id')\n",
    "\n",
    "def process_existing_files(path, handler):\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(path, filename)\n",
    "            handler.process_new_file(file_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path_to_watch = r\"C:\\Users\\Juan Daniel Bermudez\\OneDrive\\Escritorio\\M6\\inventory_prueba\\CSV_Finales\"  # Cambia esto por tu ruta\n",
    "    event_handler = DataHandler(engine)\n",
    "\n",
    "    # Procesar archivos existentes en la carpeta\n",
    "    process_existing_files(path_to_watch, event_handler)\n",
    "\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, path=path_to_watch, recursive=True)\n",
    "    observer.start()\n",
    "    print(f\"Observando cambios en: {path_to_watch}\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        observer.stop()\n",
    "    observer.join()\n",
    "    print(\"El observador ha sido detenido.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
